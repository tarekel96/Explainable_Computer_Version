{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR_PATH = '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_df(df, img_scale):\n",
    "    pil_imgs = []\n",
    "    preprocessed_imgs = []\n",
    "    flattened_imgs = []\n",
    "    for i in range(len(df)):\n",
    "        img_file = df['img_file'][i]\n",
    "        img = image.load_img(img_file.strip(), target_size=(img_scale, img_scale), interpolation='lanczos')\n",
    "        img_array = image.img_to_array(img)\n",
    "        x = np.expand_dims(img_array, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preprocessed_imgs.append(x)\n",
    "        flat_img = x.flatten()\n",
    "        flattened_imgs.append(flat_img)\n",
    "        pil_imgs.append(img)\n",
    "    pil_imgs = np.array(pil_imgs)\n",
    "    preprocessed_imgs = np.array(preprocessed_imgs)\n",
    "    flattened_imgs = np.array(flattened_imgs)\n",
    "    return (pil_imgs, preprocessed_imgs, flattened_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['img', 'label']\n",
    "\n",
    "img_32_array = np.load(BASE_DIR_PATH + '', allow_pickle=True)\n",
    "img_32_df = pd.DataFrame(img_32_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create HOG Dataframes\n",
    "hog_img_32_array = []\n",
    "img_scale = 32\n",
    "\n",
    "for i in range(len(img_32_df)):\n",
    "    img, label = img_32_df['img'][i], img_32_df['label'][i]\n",
    "    hog_fd, hog_img = hog(\n",
    "        image=np.array(preprocess_input).reshape(img_scale, img_scale,3),\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8,8),\n",
    "        cells_per_block=(2,2),\n",
    "        visualize=True,\n",
    "        channel_axis=2\n",
    "    )\n",
    "    hog_img_32_array.append(img, hog_fd, hog_img, label)\n",
    "\n",
    "hog_img_32_array = np.array(hog_img_32_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_column_names = ['img', 'hog_fd', 'hog_img', 'label']\n",
    "\n",
    "hog_img_32_df = pd.DataFrame(hog_img_32_array, columns=hog_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def get_model_scores(y_test, y_pred):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    total_samples_per_class = cm.sum(axis=1)\n",
    "    accuracies_per_class = cm.diagonal() / total_samples_per_class\n",
    "\n",
    "    class_0_accuracy = accuracies_per_class[0]\n",
    "    class_1_accuracy = accuracies_per_class[1]\n",
    "\n",
    "    metrics = (acc, prec, recall, f1, roc, class_0_accuracy, class_1_accuracy)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def k_fold_scores(model, df_img, df_hog_img, model_name=None, n_splits=10, seed=12172023) -> dict:\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    rand_list = random.sample(range(0, len(df_img)), len(df_img))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    k_fold_results = {}\n",
    "\n",
    "    # Vectorized images\n",
    "    randomized_imgs = []\n",
    "\n",
    "    # shuffle records according to rand_list\n",
    "    for i in range(len(df_img)):\n",
    "        ind = rand_list[i]\n",
    "        flat_img, outcome = df_img['flat_img_array'][ind], df_img['outcome'][ind]\n",
    "        randomized_imgs.append(np.array([flat_img, outcome]))\n",
    "\n",
    "    randomized_imgs = np.array(randomized_imgs)\n",
    "\n",
    "    X, y = randomized_imgs[:, 0], randomized_imgs[:, 1]\n",
    "\n",
    "    wide_X = np.zeros((len(X), X[0].shape[0]))\n",
    "    for indx in range(len(X)):\n",
    "        for feature in range(X[0].shape[0]):\n",
    "            wide_X[indx][feature] = X[indx][feature]\n",
    "    \n",
    "    y = y.astype(int)\n",
    "\n",
    "    # Vectorized Stratified K-Fold\n",
    "    acc_scores = []\n",
    "    prec_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    roc_scores = []\n",
    "    class_0_acc_scores = []\n",
    "    class_1_acc_scores = []\n",
    "\n",
    "    for train_indx, test_indx in skf.split(wide_X, y):\n",
    "        X_train, X_test = wide_X[train_indx], wide_X[test_indx]\n",
    "        y_train, y_test = y[train_indx], y[test_indx]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc, prec, recall, f1, roc, class_0_accuracy, class_1_accuracy = get_model_scores(y_test, y_pred)\n",
    "        acc_scores.append(acc); prec_scores.append(prec)\n",
    "        recall_scores.append(recall); f1_scores.append(f1)\n",
    "        roc_scores.append(roc); class_0_acc_scores.append(class_0_accuracy)\n",
    "        class_1_acc_scores.append(class_1_accuracy)\n",
    "\n",
    "    avg_acc = np.mean(acc_scores)\n",
    "    avg_prec_scores = np.mean(prec_scores)\n",
    "    avg_recall_scores = np.mean(recall_scores)\n",
    "    avg_f1_scores = np.mean(f1_scores)\n",
    "    avg_roc_scores = np.mean(roc_scores)\n",
    "    avg_class_0_acc_scores = np.mean(class_0_acc_scores)\n",
    "    avg_class_1_acc_scores = np.mean(class_1_acc_scores)\n",
    "\n",
    "    if model_name is not None:\n",
    "        print(f'(Vectorized) {model_name} Model Stratified {n_splits}-Fold Results:')\n",
    "    print(f'{avg_acc}')\n",
    "    print(f'{avg_prec_scores=}')\n",
    "    print(f'{avg_recall_scores=}')\n",
    "    print(f'{avg_f1_scores=}')\n",
    "    print(f'{avg_roc_scores=}')\n",
    "    print(f'{avg_class_0_acc_scores=}')\n",
    "    print(f'{avg_class_1_acc_scores=}')\n",
    "\n",
    "    k_fold_results['flat_img_results'] = (avg_acc, avg_prec_scores, avg_recall_scores, avg_f1_scores, avg_roc_scores, avg_class_0_acc_scores, avg_class_1_acc_scores)\n",
    "\n",
    "    # HOG\n",
    "    hog_records = []\n",
    "\n",
    "    for i in range(len(df_hog_img)):\n",
    "        ind = rand_list[i]\n",
    "        hog_fd, outcome = df_hog_img['hog_fd'][ind], df_hog_img['outcome'][ind]\n",
    "        hog_records.append(np.array([hog_fd, outcome]))\n",
    "\n",
    "    hog_records = np.array(hog_records)\n",
    "\n",
    "    hog_X, hog_y = hog_records[:, 0], hog_records[:, 1]\n",
    "\n",
    "    hog_wide_X = np.zeros((len(hog_X), hog_X[0].shape))\n",
    "    for indx in range(len(hog_X)):\n",
    "        for feature in range(hog_X[0].shape[0]):\n",
    "            hog_wide_X[indx][feature] = hog_X[indx][feature]\n",
    "\n",
    "    # HOG Stratified K-Fold\n",
    "    hog_acc_scores = []\n",
    "    hog_prec_scores = []\n",
    "    hog_recall_scores = []\n",
    "    hog_f1_scores = []\n",
    "    hog_roc_scores = []\n",
    "    hog_class_0_acc_scores = []\n",
    "    hog_class_1_acc_scores = []\n",
    "\n",
    "    for train_indx, test_indx in skf.split(hog_wide_X, hog_y):\n",
    "        X_train, X_test = hog_wide_X[train_indx], hog_wide_X[test_indx]\n",
    "        y_train, y_test = hog_y[train_indx], hog_y[test_indx]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc, prec, recall, f1, roc, class_0_accuracy, class_1_accuracy = get_model_scores(y_test, y_pred)\n",
    "        hog_acc_scores.append(acc); hog_prec_scores.append(prec)\n",
    "        hog_recall_scores.append(recall); hog_f1_scores.append(f1)\n",
    "        hog_roc_scores.append(roc); hog_class_0_acc_scores.append(class_0_accuracy)\n",
    "        hog_class_1_acc_scores.append(class_1_accuracy)\n",
    "    \n",
    "    hog_avg_acc = np.mean(hog_acc_scores)\n",
    "    hog_avg_prec_scores = np.mean(hog_prec_scores)\n",
    "    hog_avg_recall_scores = np.mean(hog_recall_scores)\n",
    "    hog_avg_f1_scores = np.mean(hog_f1_scores)\n",
    "    hog_avg_roc_scores = np.mean(hog_roc_scores)\n",
    "    hog_avg_class_0_acc_scores = np.mean(hog_class_0_acc_scores)\n",
    "    hog_avg_class_1_acc_scores = np.mean(hog_class_1_acc_scores)\n",
    "\n",
    "    if model_name is not None:\n",
    "        print(f'(HOG) {model_name} Model Stratified {n_splits}-Fold Results:')\n",
    "    print(f'{hog_avg_acc}')\n",
    "    print(f'{hog_avg_prec_scores=}')\n",
    "    print(f'{hog_avg_recall_scores=}')\n",
    "    print(f'{hog_avg_f1_scores=}')\n",
    "    print(f'{hog_avg_roc_scores=}')\n",
    "    print(f'{hog_avg_class_0_acc_scores=}')\n",
    "    print(f'{hog_avg_class_1_acc_scores=}')\n",
    "\n",
    "    k_fold_results['hog_results'] = (hog_avg_acc, hog_avg_prec_scores, hog_avg_recall_scores, hog_avg_f1_scores, hog_avg_roc_scores, hog_avg_class_0_acc_scores, hog_avg_class_1_acc_scores)\n",
    "\n",
    "    return k_fold_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def today_date():\n",
    "    return f'{datetime.today().month}.{datetime.today().day}.{datetime.today().year}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_0_accuracy(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    total_samples_per_class = cm.sum(axis=1)\n",
    "    accuracies_per_class = cm.diagonal() / total_samples_per_class\n",
    "    class_0_accuracy = accuracies_per_class[0]\n",
    "    return class_0_accuracy\n",
    "\n",
    "def class_1_accuracy(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    total_samples_per_class = cm.sum(axis=1)\n",
    "    accuracies_per_class = cm.diagonal() / total_samples_per_class\n",
    "    class_1_accuracy = accuracies_per_class[1]\n",
    "    return class_1_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline (HOG + SVM hyperparameter tuning)\n",
    "\n",
    "import logging\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class HOGTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, orientations=9, pixels_per_cell=(8,8),\n",
    "                 cells_per_block=(2,2)):\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        hog_X = []\n",
    "        img_scale = X[0].shape[1]\n",
    "\n",
    "        for x in X:\n",
    "            hog_fd, _ = hog(\n",
    "                image=np.array(x).reshape((img_scale, img_scale, 3)),\n",
    "                orientations=self.orientations,\n",
    "                pixels_per_cell=self.pixels_per_cell,\n",
    "                cells_per_block=self.cells_per_block,\n",
    "                visualize=True,\n",
    "                channel_axis=2\n",
    "            )\n",
    "            hog_X.append(hog_fd)\n",
    "        \n",
    "        hog_X = np.array(hog_X)\n",
    "\n",
    "        hog_wide_X = np.zeros((len(hog_X), hog_X[0].shape[0]))\n",
    "        for indx in range(len(hog_X)):\n",
    "            for feature in range(hog_X[0].shape):\n",
    "                hog_wide_X[indx][feature] = hog_X[indx][feature]\n",
    "        \n",
    "        return hog_wide_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_svm_hyperparameter_tester(img_df, param_grid, experiment_name, n_splits=3, seed=12172023):\n",
    "    \n",
    "    # preprocessed_img = PIL image\n",
    "    X, y = np.array(img_df['preprocessed_img'][:]), np.array(img_df['outcome'][:]).astype(int)\n",
    "\n",
    "    log_file = './experiment_logs/{}_{}'.format(today_date(), experiment_name)\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file, mode='w')\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    scorers = {\n",
    "        'roc_auc': make_scorer(roc_auc_score),\n",
    "        'class_0_accuracy': make_scorer(class_0_accuracy),\n",
    "        'class_1_accuracy': make_scorer(class_1_accuracy),\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'recall': make_scorer(recall_score),\n",
    "        'f1': make_scorer(f1_score)\n",
    "    }\n",
    "\n",
    "    # pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('HOG', HOGTransformer()),\n",
    "        ('SVM', SVC())\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scorers,\n",
    "        refit='roc_auc',\n",
    "        cv=skf,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    cv_results = grid_search.cv_results_\n",
    "    for i in range(len(cv_results['params'])):\n",
    "        print('Parameters: {}'.format(cv_results['params'][i]))\n",
    "        logging.info('Parameters: {}'.format(cv_results['params'][i]))\n",
    "        for scorer in scorers:\n",
    "            print('{}: {}'.format(scorer, cv_results[f'mean_test_{scorer}'][i]))\n",
    "            logging.info('{}: {}'.format(scorer, cv_results[f'mean_test_{scorer}'][i]))\n",
    "        print('\\n'); logging.info('\\n')\n",
    "    \n",
    "    print('Best parameters found: {}'.format(grid_search.best_params_))\n",
    "    print('Best cross-validated ROC AUC Score: {}'.format(grid_search.best_score_))\n",
    "    logging.info('Best parameters found: {}'.format(grid_search.best_params_))\n",
    "    logging.info('Best cross-validated ROC AUC Score: {}'.format(grid_search.best_score_))\n",
    "\n",
    "    try:\n",
    "        file_handler.close()\n",
    "    except Exception as e:\n",
    "        print('Error shutting down the logging.\\nError msg: {}'.format(e))\n",
    "        pass\n",
    "\n",
    "    return grid_search"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
